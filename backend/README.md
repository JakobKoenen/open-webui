# Agentic AI Planner Backend

FastAPI Backend fÃ¼r den Agentic AI Planner Step mit Azure OpenAI Integration.

## ğŸ¯ FunktionalitÃ¤t

Dieses Backend stellt einen Agentic AI Planner Agent bereit, der:
- Benutzeranfragen analysiert
- Strukturierte PlÃ¤ne erstellt
- Priorisierte Schritte generiert
- Komplexe Aufgaben zerlegt

## ğŸš€ Schnellstart

### Mit Docker (empfohlen)

```bash
# Aus dem Hauptverzeichnis
docker-compose up -d planner-backend
```

### Lokale Entwicklung

```bash
cd backend

# Virtual Environment erstellen
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Dependencies installieren
pip install -r requirements.txt

# Server starten
python main.py
```

Der Server lÃ¤uft auf `http://localhost:8000`

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET /health
```

### Planner Step
```bash
POST /api/v1/planner
```

**Request Body:**
```json
{
  "message": "Erstelle einen Plan fÃ¼r X",
  "conversation_history": [
    {"role": "user", "content": "Vorherige Nachricht"},
    {"role": "assistant", "content": "Vorherige Antwort"}
  ]
}
```

**Response:**
```json
{
  "result": "Strukturierter Plan...",
  "status": "success"
}
```

### Chat Endpoint
```bash
POST /api/v1/chat
```
Alias fÃ¼r `/api/v1/planner` - fÃ¼r einfache Chat-Integration.

## âš™ï¸ Konfiguration

### Environment Variables

Kopieren Sie `env.template` zu `.env` und konfigurieren Sie:

```bash
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-15-preview
BACKEND_PORT=8000
```

### Azure OpenAI Setup

1. Erstellen Sie eine Azure OpenAI Resource im Azure Portal
2. Stellen Sie ein Modell bereit (z.B. GPT-4, GPT-3.5-turbo)
3. Kopieren Sie Endpoint und API Key
4. FÃ¼gen Sie diese in `.env` ein

## ğŸ”§ Entwicklung

### Dependencies

- `fastapi`: Web Framework
- `uvicorn`: ASGI Server
- `openai`: Azure OpenAI Client
- `pydantic`: Data Validation
- `python-dotenv`: Environment Variables

### Struktur

```
backend/
â”œâ”€â”€ main.py              # FastAPI Application
â”œâ”€â”€ requirements.txt     # Python Dependencies
â”œâ”€â”€ Dockerfile          # Docker Image
â”œâ”€â”€ .dockerignore       # Docker Ignore Rules
â””â”€â”€ README.md           # Diese Datei
```

## ğŸ“š Dokumentation

Nach dem Start ist die API Dokumentation verfÃ¼gbar unter:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## ğŸ”Œ Open WebUI Integration

Das Backend ist fÃ¼r die Integration mit Open WebUI vorbereitet:

1. Backend lÃ¤uft auf Port 8000
2. Open WebUI lÃ¤uft auf Port 3000
3. Beide Services sind im gleichen Docker Network
4. Open WebUI kann das Backend via `http://planner-backend:8000` erreichen

## ğŸ§ª Testing

```bash
# Health Check
curl http://localhost:8000/health

# Planner Test
curl -X POST http://localhost:8000/api/v1/planner \
  -H "Content-Type: application/json" \
  -d '{"message": "Erstelle einen Plan fÃ¼r ein neues Projekt"}'
```

## ğŸ“ Logs

```bash
# Docker Logs
docker logs -f agentic-ai-planner-backend

# Docker Compose Logs
docker-compose logs -f planner-backend
```

## ğŸ”„ Erweiterte Konfiguration

### System Prompt anpassen

Bearbeiten Sie `PLANNER_SYSTEM_PROMPT` in `main.py` fÃ¼r spezifische Anforderungen.

### Model Parameters

Anpassen in der `planner_step` Funktion:
```python
response = client.chat.completions.create(
    model=AZURE_OPENAI_DEPLOYMENT_NAME,
    messages=messages,
    temperature=0.7,    # KreativitÃ¤t (0.0-1.0)
    max_tokens=2000     # Max. Ausgabe-LÃ¤nge
)
```
